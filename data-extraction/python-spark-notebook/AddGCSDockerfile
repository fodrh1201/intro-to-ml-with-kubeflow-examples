ARG base
FROM $base

# Set an enviroment variable for where we are going to put spark
ENV SPARK_HOME /opt/spark

# Add access to GCS
RUN rm $SPARK_HOME/jars/guava-14.0.1.jar
ADD http://maven-central.storage.googleapis.com/maven2/com/google/guava/guava/23.0/guava-23.0.jar $SPARK_HOME/jars
# Add the connector jar needed to access Google Cloud Storage using the Hadoop FileSystem API.
ADD https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar $SPARK_HOME/jars

# Install python3.6 and some libraries
RUN mkdir -p /usr/share/man/man1 # See https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=863199
RUN apt-get update && \
    DEBIAN_FRONTEND=noninteractive apt-get install -y -q python3.6 python3-pip && \
    rm -rf /var/cache/apt
RUN pip3 install pandas pyarrow==0.11.0 spacy
