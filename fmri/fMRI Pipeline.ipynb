{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## God damned this is stupid\n",
    "\n",
    "But i guess you need to create the CRD for SparkApps first...\n",
    "\n",
    "```\n",
    "kubectl -n kubeflow create -f https://raw.githubusercontent.com/GoogleCloudPlatform/spark-on-k8s-operator/master/manifest/crds/sparkoperator.k8s.io_sparkapplications.yaml\n",
    "```\n",
    "\n",
    "Then \n",
    "```\n",
    "kubectl -n kubeflow get customresourcedefinitions | grep spark\n",
    "```\n",
    "\n",
    "to make sure its there...\n",
    "\n",
    "Then you have to bless the `pipeline-runner` with the neccessary karma:\n",
    "\n",
    "```\n",
    "kubectl -n kubeflow edit clusterrole pipeline-runner\n",
    "```\n",
    "\n",
    "add\n",
    "\n",
    "```\n",
    "- apiGroups:\n",
    "  - \"sparkoperator.k8s.io\"\n",
    "  resources:\n",
    "  - sparkapplications\n",
    "  verbs:\n",
    "  - '*'\n",
    "```\n",
    "at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --user kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "\n",
    "container_manifest = {\n",
    "    \"apiVersion\": \"sparkoperator.k8s.io/v1beta2\",\n",
    "    \"kind\": \"SparkApplication\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"fmri-example-phase3\",\n",
    "        \"namespace\": \"kubeflow\"\n",
    "    },\n",
    "  \"spec\": {\n",
    "      \"type\": \"Scala\",\n",
    "      \"mode\": \"cluster\",\n",
    "      \"image\": \"gcr.io/boos-demo-projects-are-rad/kf-steps/kubeflow/spark-with-dsvd:v1\",\n",
    "      \"imagePullPolicy\": \"Always\",\n",
    "      \"mainClass\": \"org.rawkintrevo.dsvd.App\",\n",
    "      \"mainApplicationFile\": \"local:///dsvd-1.0-SNAPSHOT-jar-with-dependencies.jar\", # See the Dockerfile\n",
    "      \"sparkVersion\": \"2.4.5\",\n",
    "      \"restartPolicy\": {\n",
    "        \"type\": \"Never\"\n",
    "      },\n",
    "      \"volumes\": [\n",
    "        {\"name\": \"datapvc\",\n",
    "          \"hostPath\": {\n",
    "            \"path\": \"/data\",\n",
    "            \"type\": \"Directory\"\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "        \n",
    "  \"driver\": {\n",
    "    \"cores\": 1,  \n",
    "    \"coreLimit\": \"1200m\",  \n",
    "    \"memory\": \"512m\",  \n",
    "    \"labels\": {\n",
    "      \"version\": \"2.4.5\",  \n",
    "    },      \n",
    "    \"serviceAccount\": \"spark-operatoroperator-sa\", # also try spark-operatoroperator-sa\n",
    "    \"volumeMounts\": [\n",
    "        {\n",
    "            \"name\": \"datapvc\",\n",
    "            \"mountPath\": \"/data\"\n",
    "        }\n",
    "    ] \n",
    "  },\n",
    "  \"executor\": {\n",
    "    \"cores\": 1,\n",
    "    \"instances\": 2,\n",
    "    \"memory\": \"512m\"  \n",
    "  },    \n",
    "  \"labels\": {\n",
    "    \"version\": \"2.4.5\"\n",
    "  },      \n",
    "  \"volumeMounts\": [\n",
    "    {\n",
    "        \"name\": \"datapvc\",\n",
    "        \"mountPath\": \"/data\"\n",
    "    }\n",
    "  ]\n",
    "  }\n",
    "}\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"fMRI Pipeline\",\n",
    "    description=\"No need to ask why.\"\n",
    ")\n",
    "def fmri_pipeline():\n",
    "    vop = dsl.VolumeOp(\n",
    "        name=\"datapvc\",\n",
    "        resource_name=\"newpvc\",\n",
    "        size=\"10Gi\",\n",
    "        modes=dsl.VOLUME_MODE_RWO\n",
    "    )\n",
    "\n",
    "    step1 = dsl.ContainerOp(\n",
    "        name=\"generatedata\",\n",
    "        image=\"rawkintrevo/r-fmri-gen:latest\",\n",
    "        command=[\"Rscript\", \"/pipelines/component/src/program.R\", \"--out\", \"/data/synthetic\"],\n",
    "        pvolumes={\"/data\": vop.volume}\n",
    "    )\n",
    "\n",
    "    step2 = dsl.ContainerOp(\n",
    "        name=\"prepdata\",\n",
    "        image=\"rawkintrevo/py-fmri-prep:0.2\",\n",
    "        command=[\"python\", \"/pipelines/component/src/program.py\"],\n",
    "        arguments=[\"/data/synthetic.nii.gz\", \"/data/s.csv\"],\n",
    "        pvolumes={\"/data\": step1.pvolume}\n",
    "    )\n",
    "    \n",
    "\n",
    "    rop = dsl.ResourceOp(\n",
    "        name=\"spark-scala-mahout-fmri\",\n",
    "        k8s_resource=container_manifest,\n",
    "        action=\"create\",\n",
    "        success_condition=\"status.applicationState.state == COMPLETED\"\n",
    "    ).after(step2)\n",
    "\n",
    "import kfp.compiler as compiler\n",
    "\n",
    "compiler.Compiler().compile(fmri_pipeline,\"fmri-pipeline.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experiment = client.create_experiment(name='fmri-pipeline-test-2')\n",
    "my_run = client.run_pipeline(my_experiment.id, 'fmri-pipeline-test', \n",
    "  'fmri-pipeline.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
